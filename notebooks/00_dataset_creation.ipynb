{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de72411a",
   "metadata": {},
   "source": [
    "#### ***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1801d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Bloque 0: imports y opciones ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b0d9e8",
   "metadata": {},
   "source": [
    "#### ***Rutas de ficheros***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bec090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloque 1: rutas ---\n",
    "PATH_RRHH         = \"../data/raw/rrhh_turno.csv\"              # año_mes, horas_teoricas, reduccion_tco, horas_ajustadas, horas_enfermedad, horas_accidente, horas_permiso, horas_netas\n",
    "PATH_INGENIERIA   = \"../data/raw/datos_referencias.csv\"       # ref_id, familia, peso_neto_kg\n",
    "PATH_MOV_ALMACEN  = \"../data/raw/almacen_movimientos.csv\"     # mov_id, material_lot_id, item_ref_id, tipo_mov, qty, fecha_ts\n",
    "PATH_COMPRAS      = \"../data/raw/compras_lotes.csv\"           # material_lot_id, laminado_id, ref_materia, qty_recibida, udm, peso_bruto, uds, fecha_recepcion_ts\n",
    "PATH_WORK_ORDERS  = \"../data/raw/ordenes_header.csv\"          # work_order_id, ref_id, familia, cliente, qty_plan, fecha_lanzamiento, due_date, planta_inicio\n",
    "PATH_HIST_OPS     = \"../data/raw/produccion_operaciones.csv\"  # work_order_id,work_order_id_raw,op_id,machine_id,machine_name,planta,op_text,ref_id,ref_id_raw,ts_ini,ts_fin,duracion_min,piezas_ok,piezas_scrap,evento,tipo_incidencia,operario_id,operario_nombre,of_impute_src,ref_impute_src,origen_fichero,origen_ruta,material_lot_id\n",
    "OUTPUT_PATH       = \"../data/raw/dataset_integrado_2025.csv\"  # salida integrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc947089",
   "metadata": {},
   "source": [
    "#### ***Limpieza y Helpers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6e4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Bloque 2: helpers de limpieza ---\n",
    "\n",
    "def norm_ref(x, width=6):\n",
    "    \"\"\"\n",
    "    Normaliza referencias:\n",
    "    - Acepta strings, ints, floats o NaN.\n",
    "    - Devuelve string left-pad con ceros a 'width' (por defecto 6).\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        s = str(x).strip()\n",
    "        if s.endswith('.0'):\n",
    "            s = s[:-2]\n",
    "        if not s.isdigit():\n",
    "            v = int(round(float(s)))\n",
    "            return str(v).zfill(width)\n",
    "        return s.zfill(width)\n",
    "    except:\n",
    "        try:\n",
    "            v = int(round(float(x)))\n",
    "            return str(v).zfill(width)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "def extract_ref_code(x, width=6):\n",
    "    \"\"\"Extrae el primer bloque numérico de una cadena (ej. '918506/118506' -> '918506').\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    m = re.search(r'(\\d{3,})', str(x))\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    return m.group(1)[-width:].zfill(width)\n",
    "\n",
    "def to_month_str(ts):\n",
    "    \"\"\"Convierte timestamp a 'YYYY-MM' string.\"\"\"\n",
    "    if pd.isna(ts):\n",
    "        return np.nan\n",
    "    return f\"{ts.year:04d}-{ts.month:02d}\"\n",
    "\n",
    "def coerce_dt(s):\n",
    "    \"\"\"to_datetime tolerante, NaT si no se puede (e.g., 'PENDING').\"\"\"\n",
    "    return pd.to_datetime(s, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0a805",
   "metadata": {},
   "source": [
    "#### ***Carga CSV's***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19b54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloque 3: carga segura de CSVs ---\n",
    "\n",
    "rrhh = pd.read_csv(PATH_RRHH, dtype=str)\n",
    "ing  = pd.read_csv(PATH_INGENIERIA, dtype=str)\n",
    "movs = pd.read_csv(PATH_MOV_ALMACEN, dtype=str)\n",
    "compr= pd.read_csv(PATH_COMPRAS, dtype=str)\n",
    "wo   = pd.read_csv(PATH_WORK_ORDERS, dtype=str)\n",
    "ops  = pd.read_csv(PATH_HIST_OPS, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0398a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRHH columnas detectadas: ['año_mes', 'horas_teoricas', 'reduccion_tco', 'horas_ajustadas', 'horas_enfermedad', 'horas_accidente', 'horas_permiso', 'horas_netas']\n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 4.1: RRHH mensual (robusto) ---\n",
    "# Limpieza de cabeceras: espacios, BOM, guiones, mayúsculas\n",
    "rrhh.columns = (rrhh.columns\n",
    "                .str.strip()\n",
    "                .str.replace('\\ufeff','', regex=False)\n",
    "                .str.replace(' ', '_')\n",
    "                .str.replace('-', '_')\n",
    "                .str.replace(r'[^0-9A-Za-z_ñáéíóúÑÁÉÍÓÚ]', '', regex=True)\n",
    "                .str.lower())\n",
    "\n",
    "# Normaliza variantes comunes\n",
    "rrhh = rrhh.rename(columns={\n",
    "    'ano_mes': 'año_mes',\n",
    "    'anio_mes': 'año_mes',\n",
    "    'mes_anio': 'año_mes',\n",
    "    'horas_teoricas_hrs': 'horas_teoricas',\n",
    "    'horas_teoricashrs': 'horas_teoricas',\n",
    "})\n",
    "\n",
    "expected = [\n",
    "    \"año_mes\",\"horas_teoricas\",\"reduccion_tco\",\"horas_ajustadas\",\n",
    "    \"horas_enfermedad\",\"horas_accidente\",\"horas_permiso\",\"horas_netas\"\n",
    "]\n",
    "\n",
    "# Crea columnas faltantes para evitar KeyError\n",
    "for c in expected:\n",
    "    if c not in rrhh.columns:\n",
    "        rrhh[c] = np.nan\n",
    "\n",
    "# Tipos\n",
    "rrhh[\"año_mes\"] = rrhh[\"año_mes\"].astype(str).str.strip()\n",
    "for c in [\"horas_teoricas\",\"reduccion_tco\",\"horas_ajustadas\",\"horas_enfermedad\",\"horas_accidente\",\"horas_permiso\",\"horas_netas\"]:\n",
    "    rrhh[c] = pd.to_numeric(rrhh[c], errors=\"coerce\")\n",
    "\n",
    "rrhh = rrhh.drop_duplicates(subset=[\"año_mes\"])\n",
    "\n",
    "print(\"RRHH columnas detectadas:\", list(rrhh.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be12912",
   "metadata": {},
   "source": [
    "#### ***Limpieza por tabla***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136ead53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56446/1068072905.py:47: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  wo[\"planta_inicio\"] = wo[\"planta_inicio\"].replace({\"PENDING\":np.nan}).astype(\"string\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Bloque 4.1: RRHH mensual ---\n",
    "rrhh[\"año_mes\"] = rrhh[\"año_mes\"].astype(str).str.strip()\n",
    "cols_num = [\"horas_teoricas\",\"reduccion_tco\",\"horas_ajustadas\",\"horas_enfermedad\",\"horas_accidente\",\"horas_permiso\",\"horas_netas\"]\n",
    "for c in cols_num:\n",
    "    rrhh[c] = pd.to_numeric(rrhh[c], errors=\"coerce\")\n",
    "rrhh = rrhh.drop_duplicates(subset=[\"año_mes\"])\n",
    "\n",
    "# --- Bloque 4.2: Ingeniería (maestro de piezas) ---\n",
    "ing[\"ref_id_str\"] = ing[\"ref_id\"].map(norm_ref)\n",
    "ing[\"familia\"] = ing[\"familia\"].astype(str).str.strip()\n",
    "ing[\"peso_neto_kg\"] = pd.to_numeric(ing[\"peso_neto_kg\"], errors=\"coerce\")\n",
    "# Evitar explosión en el merge: quitar refs nulas y duplicadas\n",
    "ing = (ing\n",
    "       .dropna(subset=[\"ref_id_str\"])\n",
    "       .drop_duplicates(subset=[\"ref_id_str\"], keep=\"first\"))\n",
    "\n",
    "# --- Bloque 4.3: Movimientos a almacén (solo IN) ---\n",
    "movs[\"fecha_ts\"] = coerce_dt(movs[\"fecha_ts\"])\n",
    "movs = movs[movs[\"tipo_mov\"].str.upper().eq(\"IN\")]\n",
    "movs[\"item_ref_id_str\"] = movs[\"item_ref_id\"].map(norm_ref)\n",
    "movs[\"qty\"] = pd.to_numeric(movs[\"qty\"], errors=\"coerce\").fillna(0)\n",
    "movs[\"fecha\"] = movs[\"fecha_ts\"].dt.normalize()  # fecha sin hora\n",
    "mov_aggr = (movs\n",
    "            .groupby([\"item_ref_id_str\",\"fecha\"], as_index=False)[\"qty\"]\n",
    "            .sum()\n",
    "            .rename(columns={\"qty\":\"qty_in_almacen_dia\"}))\n",
    "\n",
    "# --- Bloque 4.4: Compras de materia prima (lotes) ---\n",
    "compr[\"fecha_recepcion_ts\"] = coerce_dt(compr[\"fecha_recepcion_ts\"])\n",
    "compr[\"material_lot_id\"] = compr[\"material_lot_id\"].astype(str).str.strip()\n",
    "# ref_materia puede venir con / o -, extraemos el primer bloque numérico\n",
    "compr[\"ref_materia_str\"] = compr[\"ref_materia\"].apply(extract_ref_code)\n",
    "for c in [\"qty_recibida\",\"peso_bruto\",\"uds\"]:\n",
    "    if c in compr:\n",
    "        compr[c] = pd.to_numeric(compr[c], errors=\"coerce\")\n",
    "# Dejamos solo filas con ref de materia y deduplicamos por lote\n",
    "compr = (compr\n",
    "         .dropna(subset=[\"ref_materia_str\"])\n",
    "         .drop_duplicates(subset=[\"material_lot_id\"], keep=\"first\"))\n",
    "\n",
    "# --- Bloque 4.5: Work orders ---\n",
    "wo[\"work_order_id\"] = wo[\"work_order_id\"].astype(str).str.strip()\n",
    "wo[\"ref_id_str\"] = wo[\"ref_id\"].map(norm_ref)\n",
    "wo[\"qty_plan\"] = pd.to_numeric(wo[\"qty_plan\"], errors=\"coerce\")\n",
    "for c in [\"fecha_lanzamiento\",\"due_date\"]:\n",
    "    wo[c] = coerce_dt(wo[c])\n",
    "wo[\"planta_inicio\"] = wo[\"planta_inicio\"].replace({\"PENDING\":np.nan}).astype(\"string\")\n",
    "# Evitar multiplicar filas: llave única work_order+ref\n",
    "wo = (wo\n",
    "      .dropna(subset=[\"work_order_id\",\"ref_id_str\"])\n",
    "      .drop_duplicates(subset=[\"work_order_id\",\"ref_id_str\"], keep=\"first\"))\n",
    "\n",
    "# --- Bloque 4.6: Histórico de operaciones ---\n",
    "ops[\"ts_ini\"] = coerce_dt(ops[\"ts_ini\"])\n",
    "ops[\"ts_fin\"] = coerce_dt(ops[\"ts_fin\"])\n",
    "ops[\"duracion_min\"] = pd.to_numeric(ops[\"duracion_min\"], errors=\"coerce\")\n",
    "ops[\"piezas_ok\"] = pd.to_numeric(ops[\"piezas_ok\"], errors=\"coerce\").fillna(0)\n",
    "ops[\"piezas_scrap\"] = pd.to_numeric(ops[\"piezas_scrap\"], errors=\"coerce\").fillna(0)\n",
    "# ref preferente: 'ref_id' si existe, si no 'ref_id_raw'\n",
    "ops[\"ref_id_str\"] = np.where(ops.get(\"ref_id\").notna(), ops[\"ref_id\"].map(norm_ref), ops.get(\"ref_id_raw\").map(norm_ref))\n",
    "# fecha de fin para agregados y joins diarios\n",
    "ops[\"fecha\"] = ops[\"ts_fin\"].dt.normalize()\n",
    "# downtime solo cuando evento=Incidencia\n",
    "ops[\"evento\"] = ops[\"evento\"].astype(str)\n",
    "ops[\"downtime_min\"] = np.where(ops[\"evento\"].str.lower().str.contains(\"incidencia\"), ops[\"duracion_min\"], 0).astype(float)\n",
    "# material_lot_id a string y 0 -> NaN\n",
    "if \"material_lot_id\" in ops:\n",
    "    ops[\"material_lot_id\"] = ops[\"material_lot_id\"].astype(str).str.strip()\n",
    "    ops.loc[ops[\"material_lot_id\"].isin([\"0\",\"0.0\",\"nan\",\"None\",\"\"]), \"material_lot_id\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f80b13",
   "metadata": {},
   "source": [
    "#### ***Unión Base Sobre Operaciones***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292daae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56446/3821203512.py:50: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ops_without_lot_valid = ops_without_lot_valid.groupby(\"ref_id_str\", group_keys=False).apply(merge_asof_ref)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Bloque 5: joins principales sobre ops ---\n",
    "\n",
    "# 5.1 Join Ingeniería (familia, peso)\n",
    "ops1 = ops.merge(ing[[\"ref_id_str\",\"familia\",\"peso_neto_kg\"]], on=\"ref_id_str\", how=\"left\")\n",
    "\n",
    "# 5.2 Join Work Orders (cliente, qty_plan, due_date, planta_inicio)\n",
    "ops2 = ops1.merge(\n",
    "    wo[[\"work_order_id\",\"ref_id_str\",\"cliente\",\"qty_plan\",\"fecha_lanzamiento\",\"due_date\",\"planta_inicio\"]],\n",
    "    on=[\"work_order_id\",\"ref_id_str\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 5.3 Join Compras por material_lot_id si existe, si no, asignar por ref y fecha (asof por referencia)\n",
    "compr_cols = [\"material_lot_id\",\"ref_materia_str\",\"qty_recibida\",\"peso_bruto\",\"uds\",\"fecha_recepcion_ts\"]\n",
    "\n",
    "ops_with_lot = ops2[ops2[\"material_lot_id\"].notna()].copy()\n",
    "ops_without_lot = ops2[ops2[\"material_lot_id\"].isna()].copy()\n",
    "\n",
    "# Join directo por lote y limpieza de sufijos\n",
    "ops_with_lot = ops_with_lot.merge(compr[compr_cols], on=\"material_lot_id\", how=\"left\", suffixes=(\"\", \"_compras\"))\n",
    "for col in [\"ref_materia_str\",\"qty_recibida\",\"peso_bruto\",\"uds\",\"fecha_recepcion_ts\"]:\n",
    "    dup = f\"{col}_compras\"\n",
    "    if dup in ops_with_lot and col in ops_with_lot:\n",
    "        ops_with_lot[col] = ops_with_lot[col].combine_first(ops_with_lot[dup])\n",
    "        ops_with_lot = ops_with_lot.drop(columns=[dup])\n",
    "\n",
    "# Asignación por referencia y fecha (último lote recibido antes de ts_fin)\n",
    "compr_asof = compr.dropna(subset=[\"ref_materia_str\",\"fecha_recepcion_ts\"]).copy()\n",
    "compr_asof[\"ref_id_str_match\"] = compr_asof[\"ref_materia_str\"]\n",
    "compr_asof = compr_asof.rename(columns={\"ref_id_str_match\":\"ref_id_str\"})\n",
    "\n",
    "asof_cols_to_drop = [\"material_lot_id\",\"ref_materia_str\",\"qty_recibida\",\"peso_bruto\",\"uds\",\"fecha_recepcion_ts\"]\n",
    "\n",
    "def merge_asof_ref(group):\n",
    "    lot_ref = compr_asof[compr_asof[\"ref_id_str\"] == group.name]\n",
    "    if lot_ref.empty:\n",
    "        return group\n",
    "    lot_ref = lot_ref.sort_values(\"fecha_recepcion_ts\").drop(columns=[\"ref_id_str\"])\n",
    "    base = group.drop(columns=asof_cols_to_drop, errors=\"ignore\")\n",
    "    return pd.merge_asof(\n",
    "        base.sort_values(\"ts_fin\"),\n",
    "        lot_ref,\n",
    "        left_on=\"ts_fin\",\n",
    "        right_on=\"fecha_recepcion_ts\",\n",
    "        direction=\"backward\"\n",
    "    )\n",
    "\n",
    "ops_without_lot_valid = ops_without_lot.dropna(subset=[\"ref_id_str\",\"ts_fin\"])\n",
    "ops_without_lot_na = ops_without_lot[ops_without_lot[[\"ref_id_str\",\"ts_fin\"]].isna().any(axis=1)]\n",
    "ops_without_lot_valid = ops_without_lot_valid.groupby(\"ref_id_str\", group_keys=False).apply(merge_asof_ref)\n",
    "ops_without_lot = pd.concat([ops_without_lot_valid, ops_without_lot_na], ignore_index=True)\n",
    "\n",
    "# Unión y orden\n",
    "ops3 = pd.concat([ops_with_lot, ops_without_lot], ignore_index=True)\n",
    "\n",
    "# 5.4 Join Movimientos IN agregados por ref y fecha (qty_in_almacen_dia)\n",
    "ops4 = ops3.merge(\n",
    "    mov_aggr.rename(columns={\"item_ref_id_str\":\"ref_id_str\"}),\n",
    "    on=[\"ref_id_str\",\"fecha\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 5.5 Join RRHH por mes de ts_fin (global, sin planta)\n",
    "ops4[\"año_mes\"] = ops4[\"ts_fin\"].dt.strftime(\"%Y-%m\")\n",
    "ops5 = ops4.merge(rrhh, on=\"año_mes\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819f334",
   "metadata": {},
   "source": [
    "#### ***Métricas Derivadas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598fc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Bloque 6: features derivadas fáciles ---\n",
    "\n",
    "total_pzs = ops5[\"piezas_ok\"] + ops5[\"piezas_scrap\"]\n",
    "ops5[\"throughput_uph\"] = np.where(ops5[\"duracion_min\"]>0, 60.0 * ops5[\"piezas_ok\"] / ops5[\"duracion_min\"], np.nan)\n",
    "ops5[\"scrap_rate\"] = np.where(total_pzs>0, ops5[\"piezas_scrap\"] / total_pzs, np.nan)\n",
    "ops5[\"consumo_materia_kg\"] = ops5[\"peso_neto_kg\"] * ops5[\"piezas_ok\"]\n",
    "\n",
    "# qty_plan: conservar el valor del header, poner 0 si falta, y crear qty_estimado como fallback\n",
    "if \"qty_plan\" in ops5:\n",
    "    total_por_of = (ops5.groupby(\"work_order_id\")[ [\"piezas_ok\",\"piezas_scrap\"] ]\n",
    "                      .sum()\n",
    "                      .sum(axis=1))\n",
    "    ops5[\"qty_estimado\"] = ops5[\"qty_plan\"]\n",
    "    ops5[\"qty_estimado\"] = ops5[\"qty_estimado\"].fillna(ops5[\"work_order_id\"].map(total_por_of))\n",
    "    ops5[\"qty_estimado\"] = ops5[\"qty_estimado\"].fillna(0)\n",
    "    ops5[\"qty_plan\"] = ops5[\"qty_plan\"].fillna(0)\n",
    "\n",
    "# Flags de peso disponible\n",
    "ops5[\"flag_sin_peso\"] = ops5[\"peso_neto_kg\"].isna() | (ops5[\"peso_neto_kg\"]<=0)\n",
    "ops5[\"flag_con_peso\"] = ~ops5[\"flag_sin_peso\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8229fbc",
   "metadata": {},
   "source": [
    "#### ***Lead time a stock (fin de operación → siguiente entrada IN)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5670bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56446/406989896.py:41: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lead_series = ends.groupby(\"ref_id_str\", group_keys=False).apply(compute_lead_for_ref)\n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 7: lead_time_al_almacen_dias (robusto, por ref) ---\n",
    "\n",
    "# 1) Preparar tablas de fechas\n",
    "ends = ops5[[\"ref_id_str\",\"ts_fin\"]].dropna().copy()\n",
    "ends[\"end_date\"] = ends[\"ts_fin\"].dt.normalize()\n",
    "ends = ends.dropna(subset=[\"ref_id_str\",\"end_date\"])\n",
    "\n",
    "mov_dates = mov_aggr[[\"item_ref_id_str\",\"fecha\"]].drop_duplicates().rename(columns={\"item_ref_id_str\":\"ref_id_str\"})\n",
    "mov_dates = mov_dates.dropna(subset=[\"ref_id_str\",\"fecha\"])\n",
    "\n",
    "# Garantizar tipos datetime\n",
    "ends[\"end_date\"] = pd.to_datetime(ends[\"end_date\"])\n",
    "mov_dates[\"fecha\"] = pd.to_datetime(mov_dates[\"fecha\"])\n",
    "\n",
    "if mov_dates.empty:\n",
    "    # Sin movimientos: no se puede calcular lead time\n",
    "    ops5[\"end_date\"] = ops5[\"ts_fin\"].dt.normalize()\n",
    "    ops5[\"lead_time_al_almacen_dias\"] = np.nan\n",
    "else:\n",
    "    # 2) Índice de movimientos por ref, ordenado\n",
    "    mov_group = {k: v.sort_values(\"fecha\")[\"fecha\"].values\n",
    "                 for k, v in mov_dates.groupby(\"ref_id_str\")}\n",
    "\n",
    "    # 3) Para cada referencia, primer movimiento >= end_date\n",
    "    def compute_lead_for_ref(sub):\n",
    "        ref = sub.name\n",
    "        end_vals = sub[\"end_date\"].values\n",
    "        stock_vals = mov_group.get(ref, None)\n",
    "        if stock_vals is None or len(stock_vals) == 0:\n",
    "            return pd.Series([np.nan]*len(sub), index=sub.index)\n",
    "        idx = np.searchsorted(stock_vals, end_vals, side=\"left\")\n",
    "        chosen = []\n",
    "        for i in idx:\n",
    "            if i >= len(stock_vals):\n",
    "                chosen.append(pd.NaT)\n",
    "            else:\n",
    "                chosen.append(stock_vals[i])\n",
    "        chosen = pd.to_datetime(chosen)\n",
    "        return (chosen - sub[\"end_date\"]).dt.days.astype(\"float\")\n",
    "\n",
    "    lead_series = ends.groupby(\"ref_id_str\", group_keys=False).apply(compute_lead_for_ref)\n",
    "    ends[\"lead_time_al_almacen_dias\"] = lead_series.values\n",
    "\n",
    "    # 4) Mapear de vuelta\n",
    "    key = ends[\"ref_id_str\"].astype(str) + \"|\" + ends[\"end_date\"].astype(str)\n",
    "    lead_map = dict(zip(key, ends[\"lead_time_al_almacen_dias\"]))\n",
    "\n",
    "    ops5[\"end_date\"] = ops5[\"ts_fin\"].dt.normalize()\n",
    "    ops5[\"__k\"] = ops5[\"ref_id_str\"].astype(str) + \"|\" + ops5[\"end_date\"].astype(str)\n",
    "    ops5[\"lead_time_al_almacen_dias\"] = ops5[\"__k\"].map(lead_map)\n",
    "    ops5 = ops5.drop(columns=[\"__k\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e1662",
   "metadata": {},
   "source": [
    "#### ***Fusión Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a70d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Bloque 8: orden final de columnas útiles ---\n",
    "\n",
    "cols_final = [\n",
    "    # claves y tiempo\n",
    "    \"work_order_id\",\"op_id\",\"machine_id\",\"machine_name\",\"planta\",\"op_text\",\n",
    "    \"ref_id_str\",\"familia\",\"peso_neto_kg\",\"material_lot_id\",\"ref_materia_str\",\n",
    "    \"ts_ini\",\"ts_fin\",\"fecha\",\"duracion_min\",\"evento\",\"tipo_incidencia\",\n",
    "    # cantidades\n",
    "    \"piezas_ok\",\"piezas_scrap\",\"qty_plan\",\"qty_estimado\",\"qty_in_almacen_dia\",\n",
    "    # rrhh\n",
    "    \"año_mes\",\"horas_teoricas\",\"reduccion_tco\",\"horas_ajustadas\",\"horas_enfermedad\",\"horas_accidente\",\"horas_permiso\",\"horas_netas\",\n",
    "    # compras\n",
    "    \"qty_recibida\",\"peso_bruto\",\"uds\",\"fecha_recepcion_ts\",\n",
    "    # derivados\n",
    "    \"throughput_uph\",\"scrap_rate\",\"downtime_min\",\"consumo_materia_kg\",\"lead_time_al_almacen_dias\",\n",
    "    # flags\n",
    "    \"flag_sin_peso\",\"flag_con_peso\",\n",
    "]\n",
    "\n",
    "# Mantén solo las que existan\n",
    "cols_final = [c for c in cols_final if c in ops5.columns]\n",
    "df = ops5[cols_final].copy()\n",
    "\n",
    "# Orden y tipos suaves\n",
    "num_cols = [\"duracion_min\",\"piezas_ok\",\"piezas_scrap\",\"qty_plan\",\"qty_estimado\",\"qty_in_almacen_dia\",\n",
    "            \"horas_teoricas\",\"reduccion_tco\",\"horas_ajustadas\",\"horas_enfermedad\",\"horas_accidente\",\"horas_permiso\",\"horas_netas\",\n",
    "            \"qty_recibida\",\"peso_bruto\",\"uds\",\"throughput_uph\",\"scrap_rate\",\"downtime_min\",\"consumo_materia_kg\",\"peso_neto_kg\",\"lead_time_al_almacen_dias\",\n",
    "            \"flag_sin_peso\",\"flag_con_peso\"]\n",
    "for c in num_cols:\n",
    "    if c in df:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea799ca3",
   "metadata": {},
   "source": [
    "#### ***Tests Finales***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4c228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas integradas: 64555\n",
      "Refs distintas: 91\n",
      "Máquinas distintas: 78\n",
      "  work_order_id    op_id machine_id machine_name   planta  op_text ref_id_str             familia  peso_neto_kg material_lot_id ref_materia_str  \\\n",
      "0       24/0767  TALLADO         49  Talladora49  Abadiño  TALLADO     000305  CORONA DE ARRANQUE           5.0             NaN             NaN   \n",
      "1       24/0767  TALLADO         49  Talladora49  Abadiño  TALLADO     000305  CORONA DE ARRANQUE           5.0             NaN             NaN   \n",
      "2       24/0767  TALLADO         49  Talladora49  Abadiño  TALLADO     000305  CORONA DE ARRANQUE           5.0             NaN             NaN   \n",
      "\n",
      "               ts_ini              ts_fin      fecha  duracion_min       evento tipo_incidencia  piezas_ok  piezas_scrap  qty_plan  qty_estimado  \\\n",
      "0 2025-01-28 00:50:00 2025-01-28 01:39:00 2025-01-28          49.0  Preparación             NaN          0             0       0.0         592.0   \n",
      "1 2025-01-28 05:17:00 2025-01-28 05:49:00 2025-01-28          32.0   Incidencia        AUSENCIA          0             0       0.0         592.0   \n",
      "2 2025-01-28 01:39:00 2025-01-28 06:29:00 2025-01-28         290.0   Producción             NaN        105             3       0.0         592.0   \n",
      "\n",
      "   qty_in_almacen_dia  año_mes  horas_teoricas  reduccion_tco  horas_ajustadas  horas_enfermedad  horas_accidente  horas_permiso  horas_netas  qty_recibida  \\\n",
      "0                 NaN  2025-01         12350.0          788.0          11562.0             752.0              0.0          390.0      10420.0           NaN   \n",
      "1                 NaN  2025-01         12350.0          788.0          11562.0             752.0              0.0          390.0      10420.0           NaN   \n",
      "2                 NaN  2025-01         12350.0          788.0          11562.0             752.0              0.0          390.0      10420.0           NaN   \n",
      "\n",
      "   peso_bruto  uds fecha_recepcion_ts  throughput_uph  scrap_rate  downtime_min  consumo_materia_kg  lead_time_al_almacen_dias  flag_sin_peso  flag_con_peso  \n",
      "0         NaN  NaN                NaT        0.000000         NaN           0.0                 0.0                        1.0          False           True  \n",
      "1         NaN  NaN                NaT        0.000000         NaN          32.0                 0.0                        1.0          False           True  \n",
      "2         NaN  NaN                NaT       21.724138    0.027778           0.0               525.0                        1.0          False           True  \n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 9: sanity checks mínimos ---\n",
    "print(\"Filas integradas:\", len(df))\n",
    "print(\"Refs distintas:\", df[\"ref_id_str\"].nunique() if \"ref_id_str\" in df else \"-\")\n",
    "print(\"Máquinas distintas:\", df[\"machine_name\"].nunique() if \"machine_name\" in df else \"-\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac86059e",
   "metadata": {},
   "source": [
    "#### ***Guardado Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9aee043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: ../data/raw/dataset_integrado_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 10: export ---\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(\"Guardado en:\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9bab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máquinas distintas: 84\n",
      "      machine_id         machine_name   planta\n",
      "45027        134         Curvadora134  Abadiño\n",
      "9             25          Curvadora25  Abadiño\n",
      "1652         122    Fresadora Hey 122  Abadiño\n",
      "4681          12          Fresadora12  Abadiño\n",
      "2200         140         Fresadora140  Abadiño\n",
      "3639         141         Fresadora141  Abadiño\n",
      "4289          80          Fresadora80  Abadiño\n",
      "40           110         Granalladora  Abadiño\n",
      "1632         517  Granalladora Sthick  Abadiño\n",
      "67           118                Horno  Abadiño\n",
      "1631         519         Horno Arrola  Abadiño\n",
      "34568       1001          Linea Luk 1  Abadiño\n",
      "23023       1002          Linea Luk 2  Abadiño\n",
      "1661        1003          Linea Luk 3  Abadiño\n",
      "22805       4001          Linea SACHS  Abadiño\n",
      "14291       3001     Linea Volkswagen  Abadiño\n",
      "62            31               PRENSA  Abadiño\n",
      "199           32               PRENSA  Abadiño\n",
      "3035          27             Prensa27  Abadiño\n",
      "44512         95           Prensa95-1  Abadiño\n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 11: listado de máquinas y top-5 por recurso ---\n",
    "\n",
    "# 11.1 Máquinas distintas\n",
    "maquinas = (df[[\"machine_id\",\"machine_name\",\"planta\"]]\n",
    "            .drop_duplicates()\n",
    "            .sort_values([\"planta\",\"machine_name\"], na_position=\"last\"))\n",
    "print(\"Máquinas distintas:\", len(maquinas))\n",
    "print(maquinas.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90c9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OF->ref resumen (primeras 10 filas):\n",
      "   work_order_id ref_id_str              familia  piezas_ok  piezas_scrap  qty_plan  total  scrap_rate  cumplimiento\n",
      "0        20/4428     109800                  nan       9056             0       0.0   9056    0.000000           NaN\n",
      "1        22/1009     003501   CORONA DE ARRANQUE        868            31     110.0    899    0.034483      7.890909\n",
      "2        23/0113     118001                  nan       4062             0       0.0   4062    0.000000           NaN\n",
      "3        23/0172     191000   CORONA DE ARRANQUE          0             0       0.0      0         NaN           NaN\n",
      "4        23/0366     818003  INKREMENT GEBERRING       9466            14       0.0   9480    0.001477           NaN\n",
      "..           ...        ...                  ...        ...           ...       ...    ...         ...           ...\n",
      "95       24/0736     902081   CORONA DE ARRANQUE      45117            63    1325.0  45180    0.001394     34.050566\n",
      "96       24/0737     190301   CORONA DE ARRANQUE      72246           157    1258.0  72403    0.002168     57.429253\n",
      "97       24/0738     190301   CORONA DE ARRANQUE      64947            84    2534.0  65031    0.001292     25.630229\n",
      "98       24/0739     190900   CORONA DE ARRANQUE      45243            70       0.0  45313    0.001545           NaN\n",
      "99       24/0740     913600   CORONA DE ARRANQUE      75790           435    3324.0  76225    0.005707     22.800842\n",
      "\n",
      "[100 rows x 9 columns]\n",
      "\n",
      "Detalle para OF 20/4428:\n",
      "  work_order_id ref_id_str familia  piezas_ok  piezas_scrap  total  scrap_rate  qty_plan  cumplimiento\n",
      "0       20/4428     109800     nan       9056             0   9056         0.0       0.0           NaN\n"
     ]
    }
   ],
   "source": [
    "# --- Bloque 12: resumen jerárquico OF -> ref -> piezas ---\n",
    "\n",
    "# 12.1 Agregado principal\n",
    "of_ref = (df.groupby([\"work_order_id\",\"ref_id_str\",\"familia\"], as_index=False)\n",
    "            .agg(piezas_ok=(\"piezas_ok\",\"sum\"),\n",
    "                 piezas_scrap=(\"piezas_scrap\",\"sum\"),\n",
    "                 qty_plan=(\"qty_plan\",\"max\"))\n",
    "         )\n",
    "of_ref[\"total\"] = of_ref[\"piezas_ok\"] + of_ref[\"piezas_scrap\"]\n",
    "of_ref[\"scrap_rate\"] = np.where(of_ref[\"total\"]>0, of_ref[\"piezas_scrap\"]/of_ref[\"total\"], np.nan)\n",
    "of_ref[\"cumplimiento\"] = np.where(of_ref[\"qty_plan\"].notna() & (of_ref[\"qty_plan\"]>0),\n",
    "                                  of_ref[\"piezas_ok\"]/of_ref[\"qty_plan\"], np.nan)\n",
    "\n",
    "print(\"OF->ref resumen (primeras 10 filas):\")\n",
    "print(of_ref.head(100))\n",
    "\n",
    "# 12.2 Vista rápida por OF concreto (cambia el ID)\n",
    "OF_EJEMPLO = of_ref[\"work_order_id\"].dropna().unique()[0] if len(of_ref)>0 else None\n",
    "if OF_EJEMPLO:\n",
    "    print(f\"\\nDetalle para OF {OF_EJEMPLO}:\")\n",
    "    print(of_ref[of_ref[\"work_order_id\"]==OF_EJEMPLO]\n",
    "          .sort_values(\"piezas_ok\", ascending=False)\n",
    "          [[\"work_order_id\",\"ref_id_str\",\"familia\",\"piezas_ok\",\"piezas_scrap\",\"total\",\"scrap_rate\",\"qty_plan\",\"cumplimiento\"]]\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
