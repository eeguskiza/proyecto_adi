"""
MÃ³dulo de chatbot con Ollama para asistir en la comprensiÃ³n de datos del dashboard.
"""

import requests
import json
import streamlit as st
import pandas as pd
from typing import Dict, Any, List, Optional


class OllamaChatbot:
    """Chatbot que utiliza Ollama para proporcionar insights sobre los datos del dashboard."""

    def __init__(self, base_url: str = "http://localhost:11434", model: str = "llama3"):
        """
        Inicializa el chatbot con Ollama.

        Args:
            base_url: URL base de Ollama (por defecto localhost:11434)
            model: Modelo a utilizar (llama3, mistral, etc.)
        """
        self.base_url = base_url
        self.model = model
        self.conversation_history = []

    def check_ollama_available(self) -> bool:
        """Verifica si Ollama estÃ¡ disponible."""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False

    def get_available_models(self) -> List[str]:
        """Obtiene la lista de modelos disponibles en Ollama."""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models_data = response.json()
                return [model['name'] for model in models_data.get('models', [])]
            return []
        except:
            return []

    def build_context_prompt(self, data_dict: Dict[str, Any], current_page: str, filtros: Dict[str, Any] = None) -> str:
        """
        Construye el prompt de contexto basado en los datos actuales del dashboard.

        Args:
            data_dict: Diccionario con los dataframes FILTRADOS del dashboard
            current_page: Nombre de la pÃ¡gina actual
            filtros: Diccionario con los filtros activos

        Returns:
            Prompt de contexto formateado
        """
        context_parts = [
            "Eres un asistente experto en anÃ¡lisis de datos de manufactura e industria.",
            "Tu objetivo es ayudar a los usuarios a comprender los datos del dashboard.",
            "Debes proporcionar insights concretos, explicar mÃ©tricas, responder preguntas y sugerir acciones especÃ­ficas.",
            "",
            f"**PÃGINA ACTUAL:** {current_page}",
            ""
        ]

        if filtros:
            context_parts.append("**FILTROS ACTIVOS:**")

            if 'date_range' in filtros and filtros['date_range']:
                fecha_inicio, fecha_fin = filtros['date_range']
                context_parts.append(f"- Rango de fechas: {fecha_inicio} a {fecha_fin}")

            if 'week_label' in filtros and filtros['week_label'] != "(Rango personalizado)":
                context_parts.append(f"- PerÃ­odo: {filtros['week_label']}")

            if 'recurso_oee' in filtros and filtros['recurso_oee'] != "(Todos)":
                context_parts.append(f"- MÃ¡quina seleccionada: {filtros['recurso_oee']}")

            if 'planta' in filtros and filtros['planta']:
                plantas_str = ", ".join(filtros['planta'])
                context_parts.append(f"- Plantas: {plantas_str}")

            context_parts.append("")
            context_parts.append("IMPORTANTE: Los datos que te proporciono ya estÃ¡n FILTRADOS segÃºn estos criterios.")
            context_parts.append("Cuando respondas, habla especÃ­ficamente de estos datos filtrados, no de datos generales.")
            context_parts.append("")

        context_parts.extend([
            "**DATOS VISIBLES EN PANTALLA (FILTRADOS):**",
            ""
        ])

        # AÃ±adir informaciÃ³n resumida de cada dataframe
        if 'produccion' in data_dict and not data_dict['produccion'].empty:
            prod = data_dict['produccion']
            total_ok = prod['piezas_ok'].sum()
            total_scrap = prod['piezas_scrap'].sum()
            total = total_ok + total_scrap
            scrap_pct = (total_scrap / total * 100) if total > 0 else 0

            context_parts.extend([
                "**PRODUCCIÃ“N:**",
                f"- Total piezas OK: {total_ok:,.0f}",
                f"- Total scrap: {total_scrap:,.0f}",
                f"- Scrap %: {scrap_pct:.2f}%",
                f"- PerÃ­odo: {prod['ts_ini'].min()} a {prod['ts_fin'].max()}",
                f"- MÃ¡quinas: {prod['machine_name'].nunique()}",
                f"- Referencias: {prod['ref_id_str'].nunique()}",
                ""
            ])

        if 'ordenes' in data_dict and not data_dict['ordenes'].empty:
            ord = data_dict['ordenes']
            context_parts.extend([
                "**Ã“RDENES:**",
                f"- Total Ã³rdenes: {ord['work_order_id'].nunique()}",
                f"- Piezas planificadas: {ord['qty_plan'].sum():,.0f}",
                ""
            ])

        if 'rrhh' in data_dict and not data_dict['rrhh'].empty:
            rrhh = data_dict['rrhh']
            cols_disponibles = rrhh.columns.tolist()

            # Buscar columna de horas disponibles (puede ser horas_netas o horas_ajustadas)
            horas_disp = 0
            if 'horas_netas' in cols_disponibles:
                horas_disp = rrhh['horas_netas'].sum()
            elif 'horas_ajustadas' in cols_disponibles:
                horas_disp = rrhh['horas_ajustadas'].sum()

            horas_perdidas = 0
            for col in ['horas_enfermedad', 'horas_accidente', 'horas_permiso']:
                if col in cols_disponibles:
                    horas_perdidas += rrhh[col].sum()

            tasa_absentismo = (horas_perdidas / (horas_disp + horas_perdidas) * 100) if (horas_disp + horas_perdidas) > 0 else 0

            context_parts.extend([
                "**RECURSOS HUMANOS:**",
                f"- Horas netas: {horas_disp:,.0f}h",
                f"- Horas perdidas: {horas_perdidas:,.0f}h",
                f"- Tasa absentismo: {tasa_absentismo:.2f}%",
                ""
            ])

        if 'compras' in data_dict and not data_dict['compras'].empty:
            comp = data_dict['compras']
            cols = comp.columns.tolist()

            # La columna puede ser qty_recibida o cantidad
            total_mp = 0
            if 'qty_recibida' in cols:
                total_mp = comp['qty_recibida'].sum()
            elif 'cantidad' in cols:
                total_mp = comp['cantidad'].sum()

            num_refs = 0
            if 'ref_materia_str' in cols:
                num_refs = comp['ref_materia_str'].nunique()
            elif 'ref_materia' in cols:
                num_refs = comp['ref_materia'].nunique()

            context_parts.extend([
                "**ALMACÃ‰N MP:**",
                f"- Total MP recibida: {total_mp:,.0f} kg",
                f"- Lotes recibidos: {len(comp)}",
                f"- Referencias MP: {num_refs}",
                ""
            ])

        context_parts.extend([
            "**CONTEXTO ESPECÃFICO DE LA PÃGINA ACTUAL:**",
            ""
        ])

        if current_page == "Cuadro de mando general" and 'produccion' in data_dict and not data_dict['produccion'].empty:
            prod = data_dict['produccion']
            maquina_seleccionada = filtros.get('recurso_oee', "(Todos)") if filtros else "(Todos)"

            if maquina_seleccionada != "(Todos)":
                context_parts.extend([
                    f"El usuario estÃ¡ visualizando el OEE de la mÃ¡quina: {maquina_seleccionada}",
                    "Puede ver grÃ¡ficos de disponibilidad, rendimiento y calidad en el tiempo.",
                    "Tu objetivo es ayudarle a entender el rendimiento de esta mÃ¡quina especÃ­fica.",
                    ""
                ])
            else:
                maquinas_disponibles = prod['machine_name'].unique().tolist()
                context_parts.extend([
                    f"El usuario estÃ¡ viendo el resumen general de {len(maquinas_disponibles)} mÃ¡quinas.",
                    f"MÃ¡quinas disponibles: {', '.join(maquinas_disponibles[:5])}{'...' if len(maquinas_disponibles) > 5 else ''}",
                    "Puede ayudarle a identificar quÃ© mÃ¡quina analizar en detalle.",
                    ""
                ])

        elif current_page == "ML - Clustering" and 'produccion' in data_dict and not data_dict['produccion'].empty:
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de Clustering de MÃ¡quinas.",
                "Esta pÃ¡gina agrupa mÃ¡quinas con caracterÃ­sticas similares usando K-Means.",
                "Se analizan: disponibilidad, scrap rate, UPH real, y duraciÃ³n de producciÃ³n.",
                "Tu objetivo es ayudarle a:",
                "  - Entender quÃ© mÃ¡quinas estÃ¡n en cada cluster",
                "  - Identificar clusters de alto/bajo rendimiento",
                "  - Sugerir acciones especÃ­ficas por cluster",
                "  - Explicar por quÃ© ciertas mÃ¡quinas estÃ¡n agrupadas",
                ""
            ])

        elif current_page == "ML - RegresiÃ³n Scrap" and 'produccion' in data_dict and not data_dict['produccion'].empty:
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de PredicciÃ³n de Scrap.",
                "Esta pÃ¡gina predice el % de scrap esperado usando Random Forest.",
                "Variables consideradas: duraciÃ³n, hora del dÃ­a, dÃ­a de semana, referencia, estado, mÃ¡quina.",
                "Tu objetivo es ayudarle a:",
                "  - Interpretar las predicciones de scrap",
                "  - Identificar quÃ© factores mÃ¡s influyen en el scrap",
                "  - Sugerir acciones para reducir el scrap predicho",
                "  - Explicar por quÃ© ciertas operaciones tienen alto scrap esperado",
                ""
            ])

        elif current_page == "ML - ClasificaciÃ³n Estado" and 'produccion' in data_dict and not data_dict['produccion'].empty:
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de ClasificaciÃ³n de Estado de MÃ¡quinas.",
                "Esta pÃ¡gina clasifica mÃ¡quinas en: EXCELENTE, BUENA, REQUIERE_ATENCION, CRITICA.",
                "Criterios: disponibilidad, scrap rate, UPH real, duraciÃ³n producciÃ³n, ratios de prep e incidencias.",
                "Tu objetivo es ayudarle a:",
                "  - Entender por quÃ© cada mÃ¡quina estÃ¡ en su categorÃ­a",
                "  - Priorizar quÃ© mÃ¡quinas atender primero (las CRITICAS)",
                "  - Sugerir acciones concretas para mejorar mÃ¡quinas REQUIERE_ATENCION",
                "  - Identificar quÃ© hacen bien las mÃ¡quinas EXCELENTES",
                ""
            ])

        elif current_page == "ProducciÃ³n" and 'produccion' in data_dict and not data_dict['produccion'].empty:
            prod = data_dict['produccion']
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de AnÃ¡lisis de ProducciÃ³n.",
                "Puede ver producciÃ³n detallada por mÃ¡quina, referencia, orden de trabajo.",
                f"Referencias producidas: {prod['ref_id_str'].nunique()}",
                f"Ã“rdenes de trabajo: {prod['work_order_id'].nunique()}",
                "Tu objetivo es ayudarle a analizar eficiencia, scrap, y cumplimiento de Ã³rdenes.",
                ""
            ])

        elif current_page == "AlmacÃ©n MP":
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de AlmacÃ©n de Materia Prima.",
                "Puede ver recepciones de MP, stock, y gestiÃ³n de inventario.",
                "Tu objetivo es ayudarle con anÃ¡lisis de consumo, disponibilidad de MP, y rotaciÃ³n.",
                ""
            ])

        elif current_page == "RRHH":
            context_parts.extend([
                "El usuario estÃ¡ en la pÃ¡gina de Recursos Humanos.",
                "Puede ver horas trabajadas, absentismo, productividad por persona.",
                "Tu objetivo es ayudarle a analizar eficiencia de personal y detectar problemas de absentismo.",
                ""
            ])

        context_parts.extend([
            "",
            "**MÃ‰TRICAS CLAVE:**",
            "- OEE: Disponibilidad Ã— Rendimiento Ã— Calidad",
            "- Disponibilidad: % tiempo produciendo vs tiempo total",
            "- Rendimiento: Velocidad real / velocidad teÃ³rica",
            "- Calidad: % piezas OK / total piezas",
            "- UPH: Unidades por hora",
            "- Scrap %: Piezas defectuosas / total",
            "",
            "**INSTRUCCIONES:**",
            "- Responde en espaÃ±ol claro y conciso",
            "- Menciona nÃºmeros especÃ­ficos de los datos cuando sea relevante",
            "- Si detectas anomalÃ­as o patrones, explÃ­calos claramente",
            "- Sugiere acciones concretas y priorizadas",
            "- Explica mÃ©tricas solo si el usuario lo pide",
            "- SÃ© directo y enfocado en resolver el problema del usuario",
            ""
        ])

        return "\n".join(context_parts)

    def chat(self, user_message: str, data_context: str) -> str:
        """
        EnvÃ­a un mensaje al chatbot y obtiene la respuesta.

        Args:
            user_message: Mensaje del usuario
            data_context: Contexto de datos para el modelo

        Returns:
            Respuesta del chatbot
        """
        try:
            messages = [
                {"role": "system", "content": data_context}
            ]

            if self.conversation_history:
                messages.extend(self.conversation_history)

            messages.append({"role": "user", "content": user_message})

            # Llamar a Ollama API
            response = requests.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model,
                    "messages": messages,
                    "stream": False
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                assistant_message = result['message']['content']

                # Actualizar historial
                self.conversation_history.append({"role": "user", "content": user_message})
                self.conversation_history.append({"role": "assistant", "content": assistant_message})

                # Limitar historial a Ãºltimos 10 mensajes para no sobrecargar
                if len(self.conversation_history) > 10:
                    self.conversation_history = self.conversation_history[-10:]

                return assistant_message
            else:
                return f"Error al comunicarse con Ollama: {response.status_code}"

        except requests.exceptions.Timeout:
            return "La solicitud ha tardado demasiado tiempo. Por favor, intenta de nuevo."
        except Exception as e:
            return f"Error: {str(e)}"

    def reset_conversation(self):
        """Reinicia el historial de conversaciÃ³n."""
        self.conversation_history = []


def render_chatbot_bubble(data_dict: Dict[str, Any], current_page: str, filtros: Dict[str, Any] = None):
    """
    Renderiza el chatbot en el sidebar de Streamlit con carga diferida.

    Args:
        data_dict: Diccionario con los datos FILTRADOS del dashboard
        current_page: Nombre de la pÃ¡gina actual
        filtros: Diccionario con los filtros activos (rango de fechas, mÃ¡quina, etc.)
    """
    # Inicializar estados mÃ­nimos
    if 'chatbot_initialized' not in st.session_state:
        st.session_state.chatbot_initialized = False
        st.session_state.chatbot = None
        st.session_state.chat_messages = []
        st.session_state.chatbot_active = False
        st.session_state.initializing = False

    # Renderizar en el sidebar
    with st.sidebar:
        st.markdown("---")

        # BotÃ³n para activar/desactivar chatbot
        if not st.session_state.chatbot_active:
            if st.button("ğŸ¤– Activar Asistente IA", width='stretch', type="primary", key="activate_chatbot"):
                st.session_state.chatbot_active = True
                st.session_state.initializing = True
                st.rerun()
        else:
            if st.button("âŒ Cerrar Asistente", width='stretch', key="deactivate_chatbot"):
                st.session_state.chatbot_active = False
                st.session_state.chatbot_initialized = False
                st.session_state.chatbot = None
                st.session_state.chat_messages = []
                st.rerun()

    # Si el chatbot estÃ¡ activo, inicializarlo y mostrar UI
    if st.session_state.chatbot_active:
        with st.sidebar:
            st.markdown("### ğŸ¤– Asistente IA")

            # Inicializar chatbot si no estÃ¡ inicializado
            if not st.session_state.chatbot_initialized:
                if st.session_state.initializing:
                    with st.spinner("Inicializando asistente IA..."):
                        try:
                            st.session_state.chatbot = OllamaChatbot()

                            # Verificar si Ollama estÃ¡ disponible
                            if st.session_state.chatbot.check_ollama_available():
                                st.session_state.chatbot_initialized = True
                                st.session_state.initializing = False
                                st.success("âœ… Asistente IA listo!")
                                st.rerun()
                            else:
                                st.session_state.initializing = False
                                st.error("âš ï¸ Ollama no disponible")
                                st.info("Ejecuta: `ollama serve`")

                                if st.button("ğŸ”„ Reintentar", key="retry_init"):
                                    st.session_state.initializing = True
                                    st.rerun()
                                return
                        except Exception as e:
                            st.session_state.initializing = False
                            st.error(f"Error: {str(e)}")
                            return
                return

            # Selector de modelo
            available_models = st.session_state.chatbot.get_available_models()
            if available_models:
                selected_model = st.selectbox(
                    "Modelo IA:",
                    available_models,
                    index=0 if st.session_state.chatbot.model not in available_models else available_models.index(st.session_state.chatbot.model),
                    key="model_selector"
                )
                if selected_model != st.session_state.chatbot.model:
                    st.session_state.chatbot.model = selected_model
                    st.session_state.chatbot.reset_conversation()
                    st.info(f"Modelo cambiado a: {selected_model}")

            st.markdown("---")

            # Mostrar historial de conversaciÃ³n
            if st.session_state.chat_messages:
                st.markdown("**ConversaciÃ³n:**")
                # Contenedor con altura fija y scroll
                with st.container():
                    for msg in st.session_state.chat_messages[-6:]:  # Ãšltimos 6 mensajes
                        if msg["role"] == "user":
                            st.markdown(f"**ğŸ§‘ TÃº:**")
                            st.info(msg['content'])
                        else:
                            st.markdown(f"**ğŸ¤– Asistente:**")
                            st.success(msg['content'])

                if st.button("ğŸ—‘ï¸ Limpiar historial", width='stretch'):
                    st.session_state.chat_messages = []
                    st.session_state.chatbot.reset_conversation()
                    st.rerun()

                st.markdown("---")

            # Input de usuario en sidebar
            user_input = st.text_area(
                "Tu pregunta:",
                placeholder="Ej: Â¿QuÃ© mÃ¡quina tiene mÃ¡s scrap?",
                height=120,
                key="chat_input_sidebar"
            )

            if st.button("ğŸ“¤ Enviar pregunta", width='stretch', type="primary", key="send_chat"):
                if user_input:
                    # AÃ±adir mensaje del usuario
                    st.session_state.chat_messages.append({
                        "role": "user",
                        "content": user_input
                    })

                    # Construir contexto
                    context = st.session_state.chatbot.build_context_prompt(data_dict, current_page, filtros)

                    # Obtener respuesta
                    with st.spinner("ğŸ¤” Pensando..."):
                        response = st.session_state.chatbot.chat(user_input, context)

                    # AÃ±adir respuesta del bot
                    st.session_state.chat_messages.append({
                        "role": "assistant",
                        "content": response
                    })

                    st.rerun()
                else:
                    st.warning("Por favor, escribe una pregunta")

            with st.expander("ğŸ’¡ Preguntas sugeridas"):
                if current_page == "Cuadro de mando general":
                    if st.button("Resumen de rendimiento", width='stretch', key="q1"):
                        st.session_state.quick_question = "Dame un resumen del rendimiento general de las mÃ¡quinas"
                    if st.button("MÃ¡quina con peor OEE", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿QuÃ© mÃ¡quina tiene el peor OEE y por quÃ©?"
                    if st.button("Tendencias preocupantes", width='stretch', key="q3"):
                        st.session_state.quick_question = "Â¿Hay alguna tendencia preocupante que deba atender?"

                elif current_page == "ML - Clustering":
                    if st.button("Interpretar clusters", width='stretch', key="q1"):
                        st.session_state.quick_question = "ExplÃ­came quÃ© significa cada cluster y quÃ© mÃ¡quinas debo priorizar"
                    if st.button("Mejores y peores grupos", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿CuÃ¡l es el cluster de mejor rendimiento y cuÃ¡l el peor?"
                    if st.button("Acciones por cluster", width='stretch', key="q3"):
                        st.session_state.quick_question = "Â¿QuÃ© acciones concretas debo tomar para cada cluster?"

                elif current_page == "ML - RegresiÃ³n Scrap":
                    if st.button("Factores clave del scrap", width='stretch', key="q1"):
                        st.session_state.quick_question = "Â¿QuÃ© factores estÃ¡n causando mÃ¡s scrap?"
                    if st.button("Reducir scrap", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿CÃ³mo puedo reducir el scrap en las operaciones?"
                    if st.button("Operaciones de alto riesgo", width='stretch', key="q3"):
                        st.session_state.quick_question = "Â¿QuÃ© operaciones tienen mayor riesgo de scrap alto?"

                elif current_page == "ML - ClasificaciÃ³n Estado":
                    if st.button("MÃ¡quinas crÃ­ticas", width='stretch', key="q1"):
                        st.session_state.quick_question = "Â¿QuÃ© mÃ¡quinas estÃ¡n en estado crÃ­tico y quÃ© debo hacer?"
                    if st.button("CÃ³mo mejorar mÃ¡quinas", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿CÃ³mo puedo mejorar las mÃ¡quinas que requieren atenciÃ³n?"
                    if st.button("Aprender de las mejores", width='stretch', key="q3"):
                        st.session_state.quick_question = "Â¿QuÃ© hacen bien las mÃ¡quinas excelentes que puedo replicar?"

                elif current_page == "ProducciÃ³n":
                    if st.button("AnÃ¡lisis de scrap", width='stretch', key="q1"):
                        st.session_state.quick_question = "Â¿CuÃ¡les son las principales causas de scrap?"
                    if st.button("Productividad por mÃ¡quina", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿QuÃ© mÃ¡quina es mÃ¡s productiva y cuÃ¡l menos?"
                    if st.button("Cumplimiento de Ã³rdenes", width='stretch', key="q3"):
                        st.session_state.quick_question = "Â¿CÃ³mo va el cumplimiento de las Ã³rdenes de trabajo?"

                else:
                    if st.button("Estado general", width='stretch', key="q1"):
                        st.session_state.quick_question = "Â¿CuÃ¡l es el estado general de los datos que estoy viendo?"
                    if st.button("Principales problemas", width='stretch', key="q2"):
                        st.session_state.quick_question = "Â¿CuÃ¡les son los principales problemas que debo atender?"
                    if st.button("Recomendaciones", width='stretch', key="q3"):
                        st.session_state.quick_question = "Dame recomendaciones concretas basadas en estos datos"

            # Procesar pregunta rÃ¡pida si existe
            if 'quick_question' in st.session_state and st.session_state.quick_question:
                question = st.session_state.quick_question
                st.session_state.quick_question = None

                st.session_state.chat_messages.append({
                    "role": "user",
                    "content": question
                })

                context = st.session_state.chatbot.build_context_prompt(data_dict, current_page, filtros)

                with st.spinner("ğŸ¤” Pensando..."):
                    response = st.session_state.chatbot.chat(question, context)

                st.session_state.chat_messages.append({
                    "role": "assistant",
                    "content": response
                })

                st.rerun()
